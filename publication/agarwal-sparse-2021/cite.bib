@article{agarwal_sparse_2021,
 abstract = {Deep reinforcement Learning for end-to-end driving is limited by the need of complex reward engineering. Sparse rewards can circumvent this challenge but suffers from long training time and leads to sub-optimal policy. In this work, we explore driving using only goal conditioned sparse rewards and propose a curriculum learning approach for end to end driving using only navigation view maps that benefit from small virtual-to-real domain gap. To address the complexity of multiple driving policies, we learn concurrent individual policies which are selected at inference by a navigation system. We demonstrate the ability of our proposal to generalize on unseen road layout, and to drive longer than in the training.},
 author = {Agarwal, Pranav and de Beaucorps, Pierre and de Charette, Raoul},
 journal = {arXiv:2103.09189 [cs]},
 keywords = {Artificial Intelligence, Computer Vision and Pattern Recognition, Robotics},
 month = {March},
 note = {arXiv: 2103.09189},
 title = {Sparse Curriculum Reinforcement Learning for End-to-End Driving},
 url = {http://arxiv.org/abs/2103.09189},
 urldate = {2021-03-19},
 year = {2021}
}

